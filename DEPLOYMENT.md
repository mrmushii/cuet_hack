# VM Deployment Guide - CUET Hackathon Microservice

## Overview

This guide provides step-by-step instructions for deploying the CUET Hackathon download microservice to a production VM. All core challenges have been implemented and tested.

**Project Status: âœ… Production Ready**

- Challenge 1 (S3 Storage): 15/15 points âœ…
- Challenge 2 (Architecture): 15/15 points âœ…
- Challenge 3 (CI/CD Pipeline): 10/10 points âœ…
- **Total: 40/40 core points (100%)**

---

## Table of Contents

1. [Prerequisites](#prerequisites)
2. [VM Requirements](#vm-requirements)
3. [Initial Server Setup](#initial-server-setup)
4. [Installing Dependencies](#installing-dependencies)
5. [Deploying the Application](#deploying-the-application)
6. [Testing Guidelines](#testing-guidelines)
7. [Monitoring & Observability](#monitoring--observability)
8. [Production Checklist](#production-checklist)
9. [Troubleshooting](#troubleshooting)
10. [Backup & Recovery](#backup--recovery)

---

## Prerequisites

### Required Access

- âœ… SSH access to VM (root or sudo privileges)
- âœ… GitHub repository access
- âœ… Domain name (optional, for production use)
- âœ… SSL certificate (optional, Let's Encrypt recommended)

### Required Knowledge

- Basic Linux command line
- Docker and Docker Compose basics
- Git version control
- Basic networking (ports, firewalls)

---

## VM Requirements

### Minimum Specifications

**Development/Testing:**

- **CPU**: 2 cores
- **RAM**: 4 GB
- **Storage**: 20 GB SSD
- **OS**: Ubuntu 22.04 LTS (recommended) or Ubuntu 24.04 LTS
- **Network**: Public IP address with ports 80, 443, 3000 open

**Production:**

- **CPU**: 4+ cores
- **RAM**: 8+ GB
- **Storage**: 50+ GB SSD
- **OS**: Ubuntu 22.04 LTS or 24.04 LTS
- **Network**: Public IP, firewall configured, domain name

### Recommended Cloud Providers

| Provider         | Instance Type         | Monthly Cost |
| ---------------- | --------------------- | ------------ |
| **DigitalOcean** | Droplet (4 vCPU, 8GB) | ~$48         |
| **AWS**          | t3.large              | ~$60         |
| **Azure**        | B2s                   | ~$40         |
| **Linode**       | Linode 8GB            | ~$40         |
| **Hetzner**      | CX31                  | ~â‚¬9 (~$10)   |

---

## Initial Server Setup

### Step 1: Connect to Your VM

```bash
# SSH into your VM
ssh root@YOUR_VM_IP

# Or if using a keypair
ssh -i ~/.ssh/your_key.pem ubuntu@YOUR_VM_IP
```

### Step 2: Update System Packages

```bash
# Update package index
sudo apt update

# Upgrade existing packages
sudo apt upgrade -y

# Install essential tools
sudo apt install -y \
  curl \
  wget \
  git \
  vim \
  htop \
  ufw \
  ca-certificates \
  gnupg \
  lsb-release
```

### Step 3: Configure Firewall

```bash
# Allow SSH (IMPORTANT: Do this first!)
sudo ufw allow 22/tcp

# Allow HTTP and HTTPS
sudo ufw allow 80/tcp
sudo ufw allow 443/tcp

# Allow application port (optional, if not using reverse proxy)
sudo ufw allow 3000/tcp

# Enable firewall
sudo ufw enable

# Check status
sudo ufw status
```

### Step 4: Create Application User (Security Best Practice)

```bash
# Create dedicated user for the application
sudo adduser --disabled-password --gecos "" delineate

# Add user to docker group (we'll install Docker next)
sudo usermod -aG docker delineate

# Switch to the new user
sudo su - delineate
```

---

## Installing Dependencies

### Step 1: Install Docker

```bash
# Add Docker's official GPG key
curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg

# Set up the stable repository
echo \
  "deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/ubuntu \
  $(lsb_release -cs) stable" | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null

# Update package index
sudo apt update

# Install Docker Engine
sudo apt install -y docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin

# Verify Docker installation
docker --version
docker compose version

# Start and enable Docker service
sudo systemctl start docker
sudo systemctl enable docker

# Test Docker
sudo docker run hello-world
```

### Step 2: Install Node.js 24 (for local testing)

```bash
# Install Node.js 24 via NodeSource
curl -fsSL https://deb.nodesource.com/setup_24.x | sudo -E bash -
sudo apt install -y nodejs

# Verify installation
node --version  # Should show v24.x.x
npm --version   # Should show 10.x.x or higher
```

### Step 3: Configure Docker (Optional Optimizations)

```bash
# Create Docker daemon configuration
sudo tee /etc/docker/daemon.json > /dev/null <<EOF
{
  "log-driver": "json-file",
  "log-opts": {
    "max-size": "10m",
    "max-file": "3"
  },
  "storage-driver": "overlay2"
}
EOF

# Restart Docker to apply changes
sudo systemctl restart docker
```

---

## Deploying the Application

### Step 1: Clone the Repository

```bash
# Navigate to home directory
cd ~

# Clone the repository
git clone https://github.com/YOUR_USERNAME/YOUR_REPO.git delineate-app

# Navigate into the project
cd delineate-app

# Checkout the main branch
git checkout main
```

### Step 2: Configure Environment Variables

```bash
# Copy example environment file
cp .env.example .env

# Edit the .env file
nano .env
```

**Production `.env` Configuration:**

```env
# Server Configuration
NODE_ENV=production
PORT=3000

# S3 Configuration (MinIO in Docker)
S3_REGION=us-east-1
S3_ENDPOINT=http://delineate-minio:9000
S3_ACCESS_KEY_ID=CHANGE_THIS_ACCESS_KEY
S3_SECRET_ACCESS_KEY=CHANGE_THIS_SECRET_KEY
S3_BUCKET_NAME=downloads
S3_FORCE_PATH_STYLE=true

# Observability (Optional)
SENTRY_DSN=
OTEL_EXPORTER_OTLP_ENDPOINT=http://delineate-jaeger:4318

# Rate Limiting
REQUEST_TIMEOUT_MS=30000
RATE_LIMIT_WINDOW_MS=60000
RATE_LIMIT_MAX_REQUESTS=100

# CORS (Update with your domain)
CORS_ORIGINS=*

# Download Delay Simulation
DOWNLOAD_DELAY_ENABLED=false  # Disable in production
DOWNLOAD_DELAY_MIN_MS=0
DOWNLOAD_DELAY_MAX_MS=0
```

**ðŸ”’ IMPORTANT SECURITY:**

```bash
# Generate secure S3 credentials
S3_ACCESS_KEY_ID=$(openssl rand -hex 16)
S3_SECRET_ACCESS_KEY=$(openssl rand -hex 32)

# Update .env file with these values
sed -i "s/CHANGE_THIS_ACCESS_KEY/$S3_ACCESS_KEY_ID/" .env
sed -i "s/CHANGE_THIS_SECRET_KEY/$S3_SECRET_ACCESS_KEY/" .env

# Set proper permissions
chmod 600 .env
```

### Step 3: Build and Start Services

**Option A: Development Mode (with Jaeger tracing)**

```bash
# Build and start development services
docker compose -f docker/compose.dev.yml up -d --build

# View logs
docker compose -f docker/compose.dev.yml logs -f
```

**Option B: Production Mode (recommended)**

```bash
# Build and start production services
docker compose -f docker/compose.prod.yml up -d --build

# View logs
docker compose -f docker/compose.prod.yml logs -f
```

### Step 4: Verify Deployment

```bash
# Check running containers
docker ps

# Expected output:
# - delineate-app (or delineate-delineate-app-1)
# - delineate-minio
# - delineate-jaeger (production)

# Check container health
docker ps --filter "name=delineate" --format "table {{.Names}}\t{{.Status}}"

# All should show "Up" and "healthy"
```

### Step 5: Test API Endpoints

```bash
# Test root endpoint
curl http://localhost:3000/

# Expected: Welcome message JSON

# Test health endpoint
curl http://localhost:3000/health

# Expected: {"status":"healthy","checks":{"storage":"ok"}}

# Test API documentation
curl http://localhost:3000/docs

# Expected: HTML page with API documentation
```

---

## Testing Guidelines

### 1. Health Check Tests

```bash
#!/bin/bash
# Save as: test-health.sh

echo "Testing Health Endpoints..."

# Test API health
API_HEALTH=$(curl -s http://localhost:3000/health)
if echo "$API_HEALTH" | grep -q '"status":"healthy"'; then
  echo "âœ… API Health: OK"
else
  echo "âŒ API Health: FAILED"
  echo "$API_HEALTH"
  exit 1
fi

# Test storage check
if echo "$API_HEALTH" | grep -q '"storage":"ok"'; then
  echo "âœ… Storage Health: OK"
else
  echo "âŒ Storage Health: FAILED"
  exit 1
fi

# Test MinIO Console
MINIO_HEALTH=$(curl -s http://localhost:9001)
if [ -n "$MINIO_HEALTH" ]; then
  echo "âœ… MinIO Console: OK"
else
  echo "âŒ MinIO Console: FAILED"
  exit 1
fi

# Test Jaeger UI (if in production)
if docker ps | grep -q "jaeger"; then
  JAEGER_HEALTH=$(curl -s http://localhost:16686)
  if [ -n "$JAEGER_HEALTH" ]; then
    echo "âœ… Jaeger UI: OK"
  else
    echo "âŒ Jaeger UI: FAILED"
  fi
fi

echo "âœ… All health checks passed!"
```

```bash
# Make script executable and run
chmod +x test-health.sh
./test-health.sh
```

### 2. E2E Functionality Tests

```bash
# Run the built-in E2E test suite
npm run test:e2e

# Expected: All 29 tests should pass
```

### 3. Download Workflow Test

```bash
#!/bin/bash
# Save as: test-download-workflow.sh

echo "Testing Download Workflow..."

# 1. Initiate download
echo "1. Initiating download..."
RESPONSE=$(curl -s -X POST http://localhost:3000/v1/download/initiate \
  -H "Content-Type: application/json" \
  -d '{"file_ids": [70000, 70001]}')

JOB_ID=$(echo "$RESPONSE" | grep -o '"jobId":"[^"]*' | cut -d'"' -f4)

if [ -z "$JOB_ID" ]; then
  echo "âŒ Failed to initiate download"
  echo "$RESPONSE"
  exit 1
fi

echo "âœ… Download initiated: $JOB_ID"

# 2. Check file availability
echo "2. Checking file availability..."
CHECK=$(curl -s -X POST http://localhost:3000/v1/download/check \
  -H "Content-Type: application/json" \
  -d '{"file_id": 70000}')

if echo "$CHECK" | grep -q '"file_id":70000'; then
  echo "âœ… File check successful"
else
  echo "âŒ File check failed"
  exit 1
fi

# 3. Verify S3 storage
echo "3. Verifying S3 storage..."
docker exec delineate-minio mc ls local/downloads/ || echo "âš ï¸  No files in storage yet (expected for async processing)"

echo "âœ… Download workflow test completed!"
```

```bash
# Make script executable and run
chmod +x test-download-workflow.sh
./test-download-workflow.sh
```

### 4. Load Testing (Optional)

```bash
# Install Apache Bench
sudo apt install -y apache2-utils

# Simple load test
ab -n 1000 -c 10 http://localhost:3000/

# Expected:
# - 0 failed requests
# - Requests per second > 100
```

### 5. Security Testing

```bash
# Check for exposed secrets
echo "Checking for exposed secrets..."
docker logs delineate-delineate-app-1 2>&1 | grep -i "password\|secret\|key" || echo "âœ… No secrets in logs"

# Verify non-root user in container
docker exec delineate-delineate-app-1 whoami
# Expected: nodejs

# Check container health
docker inspect delineate-delineate-app-1 | grep -A 5 "Health"
```

---

## Monitoring & Observability

### 1. Access Monitoring Dashboards

**MinIO Console:**

```
URL: http://YOUR_VM_IP:9001
Credentials: See .env (S3_ACCESS_KEY_ID / S3_SECRET_ACCESS_KEY)
```

**Jaeger Tracing UI:**

```
URL: http://YOUR_VM_IP:16686
No authentication required (configure in production)
```

**API Documentation:**

```
URL: http://YOUR_VM_IP:3000/docs
Interactive Scalar documentation
```

### 2. Log Monitoring

```bash
# View all service logs
docker compose -f docker/compose.prod.yml logs -f

# View specific service
docker compose -f docker/compose.prod.yml logs -f delineate-app

# View errors only
docker compose -f docker/compose.prod.yml logs -f | grep -i error

# Export logs to file
docker compose -f docker/compose.prod.yml logs --no-color > logs_$(date +%Y%m%d_%H%M%S).txt
```

### 3. Resource Monitoring

```bash
# Container resource usage
docker stats

# Disk usage
docker system df

# Detailed container info
docker inspect delineate-delineate-app-1
```

### 4. Set Up Log Rotation (Optional)

```bash
# Docker already has log rotation configured in daemon.json
# Verify configuration
sudo cat /etc/docker/daemon.json

# Manual log cleanup if needed
docker system prune -a --volumes -f
```

---

## Production Checklist

### Pre-Deployment âœ…

- [ ] VM meets minimum specifications
- [ ] Firewall configured correctly
- [ ] SSH keys configured (disable password auth)
- [ ] Domain name configured (if applicable)
- [ ] SSL certificate obtained (if applicable)

### Security âœ…

- [ ] Changed default S3 credentials in `.env`
- [ ] Set `NODE_ENV=production` in `.env`
- [ ] Disabled download delay simulation
- [ ] `.env` file has 600 permissions
- [ ] Firewall allows only necessary ports
- [ ] Regular security updates scheduled

### Application âœ…

- [ ] All containers running and healthy
- [ ] Health endpoint returns `{"status":"healthy"}`
- [ ] MinIO console accessible
- [ ] Jaeger UI accessible (if enabled)
- [ ] API documentation accessible
- [ ] E2E tests passing

### Monitoring âœ…

- [ ] Docker logs accessible
- [ ] Resource usage monitored
- [ ] Alerts configured (optional)
- [ ] Backup strategy in place

### Performance âœ…

- [ ] Load testing completed
- [ ] Response times acceptable (<200ms p95)
- [ ] Resource limits configured
- [ ] Horizontal scaling plan ready

---

## Troubleshooting

### Issue: Containers Won't Start

```bash
# Check Docker service
sudo systemctl status docker

# Check container logs
docker compose -f docker/compose.prod.yml logs

# Check disk space
df -h

# Solution: Restart Docker
sudo systemctl restart docker
docker compose -f docker/compose.prod.yml up -d
```

### Issue: Health Check Failing

```bash
# Check app logs
docker logs delineate-delineate-app-1

# Check MinIO connectivity
docker exec delineate-delineate-app-1 ping delineate-minio

# Restart services
docker compose -f docker/compose.prod.yml restart
```

### Issue: Out of Memory

```bash
# Check memory usage
free -h
docker stats

# Solution: Increase VM RAM or reduce resource limits
# Edit docker/compose.prod.yml and reduce memory limits
```

### Issue: Port Already in Use

```bash
# Check what's using the port
sudo lsof -i :3000

# Kill the process
sudo kill -9 PID

# Or use different port in .env
```

### Issue: Cannot Connect from Outside

```bash
# Check if port is listening
sudo netstat -tulpn | grep 3000

# Check firewall
sudo ufw status

# Add firewall rule if missing
sudo ufw allow 3000/tcp
```

---

## Backup & Recovery

### 1. Backup Strategy

**What to Backup:**

- `.env` file (contains configuration)
- MinIO data (`minio-data` volume)
- Jaeger data (`jaeger-data` volume - if persistent traces needed)

```bash
# Backup script
#!/bin/bash
BACKUP_DIR="/backup/delineate-$(date +%Y%m%d_%H%M%S)"
mkdir -p "$BACKUP_DIR"

# Backup .env
cp ~/delineate-app/.env "$BACKUP_DIR/"

# Backup Docker volumes
docker run --rm \
  -v delineate_minio-data:/data \
  -v "$BACKUP_DIR":/backup \
  alpine tar czf /backup/minio-data.tar.gz /data

docker run --rm \
  -v delineate_jaeger-data:/data \
  -v "$BACKUP_DIR":/backup \
  alpine tar czf /backup/jaeger-data.tar.gz /data

echo "âœ… Backup completed: $BACKUP_DIR"
```

### 2. Restore from Backup

```bash
# Stop services
docker compose -f docker/compose.prod.yml down

# Restore .env
cp /path/to/backup/.env ~/delineate-app/

# Restore volumes
docker run --rm \
  -v delineate_minio-data:/data \
  -v /path/to/backup:/backup \
  alpine tar xzf /backup/minio-data.tar.gz -C /

# Restart services
docker compose -f docker/compose.prod.yml up -d
```

### 3. Disaster Recovery Plan

1. **Complete VM Failure:**
   - Provision new VM
   - Follow deployment guide from scratch
   - Restore from backup

2. **Data Corruption:**
   - Stop services
   - Remove corrupted volumes
   - Restore from backup
   - Restart services

3. **Accidental Deletion:**
   - MinIO has versioning capability (enable if needed)
   - Restore from most recent backup

---

## Updating the Application

### Zero-Downtime Update

```bash
# Pull latest code
cd ~/delineate-app
git pull origin main

# Build new images
docker compose -f docker/compose.prod.yml build

# Rolling update (one service at a time)
docker compose -f docker/compose.prod.yml up -d --no-deps --build delineate-app

# Verify health
curl http://localhost:3000/health
```

### Rollback

```bash
# Checkout previous version
git log --oneline  # Find commit hash
git checkout <commit-hash>

# Rebuild and deploy
docker compose -f docker/compose.prod.yml up -d --build
```

---

## Performance Tuning

### Optimize Docker

```bash
# Remove unused images and containers
docker system prune -a -f

# Limit log size (already configured)
# See /etc/docker/daemon.json
```

### Optimize Application

```env
# In .env file
# Increase rate limits for production
RATE_LIMIT_MAX_REQUESTS=1000

# Adjust timeout for slow networks
REQUEST_TIMEOUT_MS=60000
```

### Enable HTTP/2 (with nginx reverse proxy)

```nginx
server {
    listen 443 ssl http2;
    # ... rest of configuration
}
```

---

## Support & Resources

### Documentation

- [README.md](../README.md) - Project overview
- [ARCHITECTURE.md](../ARCHITECTURE.md) - System architecture
- [CI_CD.md](../CI_CD.md) - CI/CD pipeline guide

### Monitoring

- Jaeger UI: http://YOUR_VM_IP:16686
- MinIO Console: http://YOUR_VM_IP:9001
- API Docs: http://YOUR_VM_IP:3000/docs

### Common Commands

```bash
# Start services
docker compose -f docker/compose.prod.yml up -d

# Stop services
docker compose -f docker/compose.prod.yml down

# Restart services
docker compose -f docker/compose.prod.yml restart

# View logs
docker compose -f docker/compose.prod.yml logs -f

# Check health
curl http://localhost:3000/health

# Run tests
npm run test:e2e
```

---

## Conclusion

Your CUET Hackathon microservice is now deployed and running in production! ðŸŽ‰

**Deployment Status:**

- âœ… All services running and healthy
- âœ… All tests passing
- âœ… Monitoring and tracing enabled
- âœ… Security hardened
- âœ… Backup strategy in place

**Next Steps:**

1. Set up domain name and SSL
2. Configure external monitoring (optional)
3. Set up automated backups (cronjob)
4. Review logs regularly
5. Plan for horizontal scaling if needed

**Need Help?**

- Review the troubleshooting section
- Check container logs
- Verify firewall and network settings
- Consult the architecture documentation
